<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Getting started · HMatrices.jl</title><meta name="title" content="Getting started · HMatrices.jl"/><meta property="og:title" content="Getting started · HMatrices.jl"/><meta property="twitter:title" content="Getting started · HMatrices.jl"/><meta name="description" content="Documentation for HMatrices.jl."/><meta property="og:description" content="Documentation for HMatrices.jl."/><meta property="twitter:description" content="Documentation for HMatrices.jl."/><meta property="og:url" content="https://IntegralEquations.github.io/HMatrices.jl/"/><meta property="twitter:url" content="https://IntegralEquations.github.io/HMatrices.jl/"/><link rel="canonical" href="https://IntegralEquations.github.io/HMatrices.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>HMatrices.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Getting started</a><ul class="internal"><li><a class="tocitem" href="#Overview"><span>Overview</span></a></li><li><a class="tocitem" href="#assemble-generic-subsection"><span>Assembling an <code>HMatrix</code></span></a></li><li><a class="tocitem" href="#Matrix-vector-product-and-iterative-solvers"><span>Matrix vector product and iterative solvers</span></a></li><li><a class="tocitem" href="#Factorization-and-direct-solvers"><span>Factorization and direct solvers</span></a></li><li><a class="tocitem" href="#Other-kernels"><span>Other kernels</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li><li><a class="tocitem" href="kernelmatrix/">Kernel matrices</a></li><li><a class="tocitem" href="dhmatrix/">Distributed HMatrix</a></li><li><span class="tocitem">Benchmarks</span><ul><li><a class="tocitem" href="benchs/">Benchmark Report for <em>HMatrices</em></a></li></ul></li><li><a class="tocitem" href="references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Getting started</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Getting started</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/IntegralEquations/HMatrices.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/IntegralEquations/HMatrices.jl/blob/main/docs/src/index.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="home-section"><a class="docs-heading-anchor" href="#home-section">HMatrices.jl</a><a id="home-section-1"></a><a class="docs-heading-anchor-permalink" href="#home-section" title="Permalink"></a></h1><p><em>A package for assembling and factoring hierarchical matrices</em></p><h2 id="Overview"><a class="docs-heading-anchor" href="#Overview">Overview</a><a id="Overview-1"></a><a class="docs-heading-anchor-permalink" href="#Overview" title="Permalink"></a></h2><p>This package provides some functionality for assembling as well as for doing linear algebra with <a href="https://en.wikipedia.org/wiki/Hierarchical_matrix">hierarchical matrices</a>. The main structure exported is the <a href="references/#HMatrices.HMatrix"><code>HMatrix</code></a> type, which can be used to efficiently approximate certain linear operators containing a hierarchical low-rank structure. Once assembled, a hierarchical matrix can be used to accelerate the solution of <code>Ax=b</code> in a variety of ways. Below you will find a quick introduction for how to <em>assemble</em> and <em>utilize</em> an <a href="references/#HMatrices.HMatrix"><code>HMatrix</code></a>; see the <a href="references/#references-section">References</a> section for more information on the available methods and structures.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Although hierarchical matrices have a broad range of application, this package focuses on their use to approximate integral operators arising in <strong>boundary integral equation (BIE)</strong> methods. As such, most of the API has been designed with BIEs in mind, and the examples that follow will focus on the compression of integral operators. Feel free to open an <a href="https://github.com/IntegralEquations/HMatrices.jl/issues/new">issue</a> or reach out if you have an interesting application of hierarchical matrices in mind not covered by this package!</p></div></div><div class="admonition is-success"><header class="admonition-header">Useful references</header><div class="admonition-body"><p>The notation and algorithms implemented were mostly drawn from the following references:</p><ul><li>Hackbusch, Wolfgang. <em>Hierarchical matrices: algorithms and analysis</em>. Vol. 49. Heidelberg: Springer, 2015.</li><li>Bebendorf, Mario. <em>Hierarchical matrices</em>. Springer Berlin Heidelberg, 2008.</li></ul></div></div><h2 id="assemble-generic-subsection"><a class="docs-heading-anchor" href="#assemble-generic-subsection">Assembling an <code>HMatrix</code></a><a id="assemble-generic-subsection-1"></a><a class="docs-heading-anchor-permalink" href="#assemble-generic-subsection" title="Permalink"></a></h2><p>In order to assemble an <a href="references/#HMatrices.HMatrix"><code>HMatrix</code></a>, you need the following (problem-specific) ingredients:</p><ol><li>The matrix-like object <code>K</code> that you wish to compress</li><li>A <code>rowtree</code> and <code>coltree</code> providing a hierarchical partition of the rows and columns of <code>K</code></li><li>An admissibility condition for determining (<em>a priory</em>) whether a block given by a node in the <code>rowtree</code> and node in the <code>coltree</code> is compressible</li><li>A function/functor to generate a low-rank approximation of compressible blocks</li></ol><p>To illustrate how this is done for a concrete problem, consider two set of points <span>$X = \left\{ \boldsymbol{x}_i \right\}_{i=1}^m$</span> and <span>$Y =\left\{\boldsymbol{x}_j \right\}_{j=1}^n$</span> in <span>$\mathbb{R}^3$</span>, and let <code>K</code> be a  <span>$m \times n$</span> matrix with entries given by:</p><p class="math-container">\[  K_{i,j} = G(\boldsymbol{x}_i,\boldsymbol{y}_j)\]</p><p>for some kernel function <span>$G$</span>. To make things simple, we will take <span>$X$</span> and <span>$Y$</span> to be points distributed on a circle:</p><pre><code class="language-julia hljs">using HMatrices, LinearAlgebra, StaticArrays
const Point2D = SVector{2,Float64}

# points on a circle
m = n = 10_000
X = Y = [Point2D(sin(i*2π/n),cos(i*2π/n)) for i in 0:n-1]
nothing</code></pre><p>Next we will create the matrix-like structure to represent the object <code>K</code>. We will pick <code>G</code> to be the free-space Greens function for Laplace&#39;s equation in two-dimensions:</p><pre><code class="language-julia hljs">struct LaplaceMatrix &lt;: AbstractMatrix{Float64}
  X::Vector{Point2D}
  Y::Vector{Point2D}
end

Base.getindex(K::LaplaceMatrix,i::Int,j::Int) = -1/2π*log(norm(K.X[i] - K.Y[j]) + 1e-10)
Base.size(K::LaplaceMatrix) = length(K.X), length(K.Y)

# create the abstract matrix
K = LaplaceMatrix(X,Y)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">10000×10000 Main.var&quot;Main&quot;.LaplaceMatrix:
 3.66468   1.17336   1.06305   0.998514  …  0.998514  1.06305   1.17336
 1.17336   3.66468   1.17336   1.06305      0.952728  0.998514  1.06305
 1.06305   1.17336   3.66468   1.17336      0.917214  0.952728  0.998514
 0.998514  1.06305   1.17336   3.66468      0.888197  0.917214  0.952728
 0.952728  0.998514  1.06305   1.17336      0.863663  0.888197  0.917214
 0.917214  0.952728  0.998514  1.06305   …  0.842411  0.863663  0.888197
 0.888197  0.917214  0.952728  0.998514     0.823665  0.842411  0.863663
 0.863663  0.888197  0.917214  0.952728     0.806896  0.823665  0.842411
 0.842411  0.863663  0.888197  0.917214     0.791727  0.806896  0.823665
 0.823665  0.842411  0.863663  0.888197     0.777879  0.791727  0.806896
 ⋮                                       ⋱                      
 0.823665  0.806896  0.791727  0.777879     0.888197  0.863663  0.842411
 0.842411  0.823665  0.806896  0.791727     0.917214  0.888197  0.863663
 0.863663  0.842411  0.823665  0.806896     0.952728  0.917214  0.888197
 0.888197  0.863663  0.842411  0.823665     0.998514  0.952728  0.917214
 0.917214  0.888197  0.863663  0.842411  …  1.06305   0.998514  0.952728
 0.952728  0.917214  0.888197  0.863663     1.17336   1.06305   0.998514
 0.998514  0.952728  0.917214  0.888197     3.66468   1.17336   1.06305
 1.06305   0.998514  0.952728  0.917214     1.17336   3.66468   1.17336
 1.17336   1.06305   0.998514  0.952728     1.06305   1.17336   3.66468</code></pre><p>The next step consists in partitioning the point clouds <code>X</code> and <code>Y</code> into a tree-like data structure so that blocks corresponding to well-separated points can be easily distinguished and compressed. The <code>IntegralEquationsBase</code> package provides the <code>ClusterTree</code> struct for this purpose (see its documentation for more details on available options):</p><pre><code class="language-julia hljs">Xclt = Yclt = ClusterTree(X)</code></pre><p>The object <code>Xclt</code> represents a tree partition of the point cloud into axis-aligned bounding boxes.</p><p>The third requirement is an <em>admissibilty condition</em> to determine if the interaction between two clusters should be compressed. We will use the <a href="references/#HMatrices.StrongAdmissibilityStd"><code>StrongAdmissibilityStd</code></a>, which is appropriate for <em>asymptotically smooth kernels</em> such as the one considered:</p><pre><code class="language-julia hljs">adm = StrongAdmissibilityStd()</code></pre><p>The final step is to provide a method to compress admissible blocks. Here we will use the <a href="references/#HMatrices.PartialACA"><code>PartialACA</code></a> functor implementing an <em>adaptive cross approximation</em> with partial pivoting strategy:</p><pre><code class="language-julia hljs">comp = PartialACA(;atol=1e-6)</code></pre><p>With these ingredients at hand, we can assemble an approximation for <code>K</code> using</p><pre><code class="language-julia hljs">H = assemble_hmatrix(K,Xclt,Yclt;adm,comp,threads=false,distributed=false)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">HMatrix of Float64 with range 1:10000 × 1:10000
	 number of nodes in tree: 3061
	 number of leaves: 2296 (760 admissible + 1536 full)
	 min rank of sparse blocks : 5
	 max rank of sparse blocks : 7
	 min length of dense blocks : 1521
	 max length of dense blocks : 1600
	 min number of elements per leaf: 1521
	 max number of elements per leaf: 1562500
	 depth of tree: 8
	 compression ratio: 22.916007
</code></pre><div class="admonition is-category-important"><header class="admonition-header">Important</header><div class="admonition-body"><p>The <a href="references/#HMatrices.assemble_hmatrix-Tuple{AbstractKernelMatrix}"><code>assemble_hmatrix</code></a> function is the main constructor exported by this package, so it is worth getting familiar with it and the various keyword arguments it accepts.</p></div></div><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>Reasonable defaults exist for the <em>admissibility condition</em>, <em>cluster tree</em>, and <em>compressor</em> when the kernel <code>K</code> is an <a href="references/#HMatrices.AbstractKernelMatrix"><code>AbstractKernelMatrix</code></a>, so that the construction process is somewhat simpler than just presented in those cases. Manually constructing each ingredient, however, gives a level of control not available through the default constructors. See the <a href="kernelmatrix/#kernelmatrix-section">Kernel matrices section</a> for more details.</p></div></div><p>You can now use <code>H</code> <em>in lieu</em> of <code>K</code> (as an approximation) for certain linear algebra operations, as shown next.</p><h2 id="Matrix-vector-product-and-iterative-solvers"><a class="docs-heading-anchor" href="#Matrix-vector-product-and-iterative-solvers">Matrix vector product and iterative solvers</a><a id="Matrix-vector-product-and-iterative-solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Matrix-vector-product-and-iterative-solvers" title="Permalink"></a></h2><p>The simplest operation you can perform with an <code>HMatrix</code> is to multiply it by a vector:</p><pre><code class="language-julia hljs">x = rand(n)
norm(H*x - K*x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">7.780929624154589e-7</code></pre><p>More advanced options (such as choosing between a threaded or serial implementation) can be accessed by calling <a href="references/#LinearAlgebra.mul!"><code>mul!</code></a> directly:</p><pre><code class="language-julia hljs">y = similar(x)
mul!(y,H,x,1,0;threads=false)
norm(y - K*x)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">7.780929786795957e-7</code></pre><p>The example below illustrates how to use the <code>HMatrix</code> <code>H</code> constructed above with the <a href="https://github.com/JuliaLinearAlgebra/IterativeSolvers.jl"><code>IterativeSolvers</code></a> package:</p><pre><code class="language-julia hljs">using IterativeSolvers
b = rand(m)
approx = gmres!(y,H,b;abstol=1e-6)
exact  = Matrix(K)\b
norm(approx-exact)/norm(exact)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">6.36774615230175e-5</code></pre><p>Internally, the hierarchical matrix <code>H</code> is stored as <code>H = inv(Pr)*_H*Pc</code>, where <code>Pr</code> and <code>Pc</code> are row and column permutation matrices induced by the clustering of the target and source points as <code>ClusterTree</code>s, respectively, and <code>_H</code> is the actual hierarchical matrix constructed. It is sometimes convenient to work directly with <code>_H</code> for performance reasons; for example, in the iterative solver above, you may want to permute rows and columns only once <em>offline</em> and perform the matrix multiplication with <code>_H</code>. The keyword argument <code>global_index=false</code> can be passed to perform the desired operations on <code>_H</code> instead, or you may overload the <a href="references/#HMatrices.use_global_index-Tuple{}"><code>HMatrices.use_global_index</code></a> method which will in turn change the default value of <code>global_index</code> throughout the package (but be careful to know what you are doing, as this may cause some <em>unexpected</em> results); similarly, you can overload <a href="references/#HMatrices.use_threads-Tuple{}"><code>HMatrices.use_threads</code></a> to globally change whether threads are used by default. In the iterative example above, for instance, we may permute the vectors <em>externally</em> before and after (but not in each forward product) as follows:</p><pre><code class="language-julia hljs">cperm  = HMatrices.colperm(H) # column permutation
rperm  = HMatrices.rowperm(H) # row permutation
bp     = b[cperm]
HMatrices.use_global_index() = false # perform operations on the local indexing system
approx = gmres!(y,H,bp;abstol=1e-6)
invpermute!(approx,rperm)
HMatrices.use_global_index() = true # go back to default
norm(approx-exact)/norm(exact)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1.3153025382887258e-8</code></pre><div class="admonition is-info"><header class="admonition-header">Problem size</header><div class="admonition-body"><p>For &quot;small&quot; problem sizes, the overhead associated with the more complex structure of an <code>HMatrix</code> will lead to computational times that are larger than the <em>dense</em> representation, even when the <code>HMatrix</code> occupies less memory. For large problem sizes, however, the loglinear complexity will yield significant gains in terms of memory and cpu time provided the underlying operator has a hierarchical low-rank structure.</p></div></div><h2 id="Factorization-and-direct-solvers"><a class="docs-heading-anchor" href="#Factorization-and-direct-solvers">Factorization and direct solvers</a><a id="Factorization-and-direct-solvers-1"></a><a class="docs-heading-anchor-permalink" href="#Factorization-and-direct-solvers" title="Permalink"></a></h2><p>Although the forward map illustrated in the example above suffices to solve the linear system <code>Kx = b</code> using an iterative solver, there are circumstances where a <em>direct</em> solver is desirable (because, e.g., the system is not well-conditioned or you wish to solve it for many right-hand-sides <code>b</code>). At present, the only available factorization is the <strong>hierarchical lu</strong> factorization of <code>H</code>, which can be accomplished as follows:</p><pre><code class="language-julia hljs">F = lu(H;atol=1e-6)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">LU factorization of HMatrix of Float64 with range 1:10000 × 1:10000
	 number of nodes in tree: 3061
	 number of leaves: 2296 (760 admissible + 1536 full)
	 min rank of sparse blocks : 4
	 max rank of sparse blocks : 7
	 min length of dense blocks : 1521
	 max length of dense blocks : 1600
	 min number of elements per leaf: 1521
	 max number of elements per leaf: 1562500
	 depth of tree: 8
	 compression ratio: 23.281982

</code></pre><p>Note that unliked the matrix-vector product, factoring <code>H</code> is not <em>exact</em> in the sense that <code>lu(H) ≠ lu(Matrix(H))</code>. The accuracy of the approximation can be controlled through the keyword arguments <code>atol,rol</code> and <code>rank</code>, which are used in the various intermediate truncations performed during the factorization. See <a href="references/#LinearAlgebra.lu-Tuple{HMatrix, Vararg{Any}}"><code>lu</code></a> for more details.</p><div class="admonition is-category-important"><header class="admonition-header">Truncation error</header><div class="admonition-body"><p>The parameters <code>atol</code> and <code>rtol</code> are used to control the truncation of low-rank blocks <em>adaptively</em> using an estimate of the true error (in Frobenius norm). These local errors may accumulate after successive truncations, meaning that the global approximation error (in Frobenius norm) may be larger than the prescribed tolerance.</p></div></div><p>The returned object <code>F</code> is of the <code>LU</code> type, and efficient routines are provided to solve linear system using <code>F</code>:</p><pre><code class="language-julia hljs">approx = F\b
norm(approx-exact)/norm(exact)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2.431705345589963e-8</code></pre><p>Note that the error in solving the linear system may be significantly larger than the error in computing <code>H*x</code> due to the condition of the underlying operator.</p><div class="admonition is-success"><header class="admonition-header">Tip</header><div class="admonition-body"><p>Because factoring an <code>HMatrix</code> with a small error tolerance can be quite time-consuming, a hybrid strategy commonly employed consists of using a rough factorization (with e.g. large tolerance or a fixed rank) as a preconditioner to an iterative solver.</p></div></div><h2 id="Other-kernels"><a class="docs-heading-anchor" href="#Other-kernels">Other kernels</a><a id="Other-kernels-1"></a><a class="docs-heading-anchor-permalink" href="#Other-kernels" title="Permalink"></a></h2><p>So far we focused on the (manual) compression of a simple kernel matrix where the entry <code>(i,j)</code> depended only on a function <code>G</code> and on point-clouds <code>X</code> and <code>Y</code>. There are many interesting applications where computing the <code>(i,j)</code> entry requires more information, such as triangles, basis functions, or normal vectors. To illustrate how the methods discussed before could be adapted lets construct a double-layer matrix for Laplace equation. To keep the example simple, we will re-use the point clouds <code>X</code> and <code>Y</code> defined before, so that we do not have to reconstruct the <em>target</em> and <em>source</em> cluster trees, and we will simply append the normal vector information to a <code>LaplaceDoubleLayer</code> structure. The implementation could look something like this:</p><pre><code class="language-julia hljs">struct LaplaceDoubleLayer &lt;: AbstractMatrix{Float64}
    X::Vector{Point2D}
    Y::Vector{Point2D}
    NY::Vector{Point2D} # normals at Y coordinate
end

function Base.getindex(K::LaplaceDoubleLayer,i::Int,j::Int)
    r = K.X[i] - K.Y[j]
    d = norm(r) + 1e-10
    return (1 / (2π) / (d^2) * dot(r, K.NY[j]))
end
Base.size(K::LaplaceDoubleLayer) = length(K.X), length(K.Y)</code></pre><p>We can now simply instantiate a double-layer kernel, and compress it as before</p><pre><code class="language-julia hljs"># create the abstract matrix
ny = Y
K = LaplaceDoubleLayer(X,Y,ny)
H = assemble_hmatrix(K,Xclt,Yclt;adm,comp,threads=false,distributed=false)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">HMatrix of Float64 with range 1:10000 × 1:10000
	 number of nodes in tree: 3061
	 number of leaves: 2296 (760 admissible + 1536 full)
	 min rank of sparse blocks : 2
	 max rank of sparse blocks : 2
	 min length of dense blocks : 1521
	 max length of dense blocks : 1600
	 min number of elements per leaf: 1521
	 max number of elements per leaf: 1562500
	 depth of tree: 8
	 compression ratio: 33.071386
</code></pre><p>With <code>H</code> assembled, everything else works exactly as before!</p><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="references/#Base.Matrix-Tuple{HMatrix}"><code>Base.Matrix</code></a></li><li><a href="references/#HMatrices.AbstractCompressor"><code>HMatrices.AbstractCompressor</code></a></li><li><a href="references/#HMatrices.AbstractHMatrix"><code>HMatrices.AbstractHMatrix</code></a></li><li><a href="references/#HMatrices.AbstractKernelMatrix"><code>HMatrices.AbstractKernelMatrix</code></a></li><li><a href="references/#HMatrices.AbstractSplitter"><code>HMatrices.AbstractSplitter</code></a></li><li><a href="references/#HMatrices.CardinalitySplitter"><code>HMatrices.CardinalitySplitter</code></a></li><li><a href="references/#HMatrices.ClusterTree"><code>HMatrices.ClusterTree</code></a></li><li><a href="references/#HMatrices.ClusterTree"><code>HMatrices.ClusterTree</code></a></li><li><a href="references/#HMatrices.DHMatrix-Union{Tuple{T}, Tuple{R}, Tuple{R, R}} where {R, T}"><code>HMatrices.DHMatrix</code></a></li><li><a href="references/#HMatrices.DHMatrix"><code>HMatrices.DHMatrix</code></a></li><li><a href="references/#HMatrices.GeometricSplitter"><code>HMatrices.GeometricSplitter</code></a></li><li><a href="references/#HMatrices.HMatrix"><code>HMatrices.HMatrix</code></a></li><li><a href="references/#HMatrices.HMatrix-Union{Tuple{T}, Tuple{R}, Tuple{R, R, Any}} where {R, T}"><code>HMatrices.HMatrix</code></a></li><li><a href="references/#HMatrices.HyperRectangle"><code>HMatrices.HyperRectangle</code></a></li><li><a href="references/#HMatrices.KernelMatrix"><code>HMatrices.KernelMatrix</code></a></li><li><a href="references/#HMatrices.MulLinearOp"><code>HMatrices.MulLinearOp</code></a></li><li><a href="references/#HMatrices.PartialACA"><code>HMatrices.PartialACA</code></a></li><li><a href="references/#HMatrices.Partition"><code>HMatrices.Partition</code></a></li><li><a href="references/#HMatrices.PermutedMatrix"><code>HMatrices.PermutedMatrix</code></a></li><li><a href="references/#HMatrices.PrincipalComponentSplitter"><code>HMatrices.PrincipalComponentSplitter</code></a></li><li><a href="references/#HMatrices.RemoteHMatrix"><code>HMatrices.RemoteHMatrix</code></a></li><li><a href="references/#HMatrices.RkMatrix"><code>HMatrices.RkMatrix</code></a></li><li><a href="references/#HMatrices.StrongAdmissibilityStd"><code>HMatrices.StrongAdmissibilityStd</code></a></li><li><a href="references/#HMatrices.TSVD"><code>HMatrices.TSVD</code></a></li><li><a href="references/#HMatrices.VectorOfVectors"><code>HMatrices.VectorOfVectors</code></a></li><li><a href="references/#HMatrices.WeakAdmissibilityStd"><code>HMatrices.WeakAdmissibilityStd</code></a></li><li><a href="references/#Base.parent-Tuple{ClusterTree}"><code>Base.parent</code></a></li><li><a href="references/#Base.split-Union{Tuple{N}, Tuple{HyperRectangle{N}, Any, Any}} where N"><code>Base.split</code></a></li><li><a href="references/#HMatrices._aca_partial"><code>HMatrices._aca_partial</code></a></li><li><a href="references/#HMatrices._aca_partial_pivot-Tuple{Any, Any}"><code>HMatrices._aca_partial_pivot</code></a></li><li><a href="references/#HMatrices._assemble_cpu!-NTuple{4, Any}"><code>HMatrices._assemble_cpu!</code></a></li><li><a href="references/#HMatrices._assemble_hmat_distributed-Tuple{Any, Any, Any}"><code>HMatrices._assemble_hmat_distributed</code></a></li><li><a href="references/#HMatrices._assemble_threads!-NTuple{4, Any}"><code>HMatrices._assemble_threads!</code></a></li><li><a href="references/#HMatrices._build_block_structure!-Union{Tuple{T}, Tuple{R}, Tuple{Any, HMatrix{R, T}}} where {R, T}"><code>HMatrices._build_block_structure!</code></a></li><li><a href="references/#HMatrices._cost_gemv-Tuple{HMatrices.RkMatrix}"><code>HMatrices._cost_gemv</code></a></li><li><a href="references/#HMatrices._hgemv_recursive!-Tuple{AbstractVector, Union{HMatrix, LinearAlgebra.Adjoint{&lt;:Any, &lt;:HMatrix}}, AbstractVector, Any}"><code>HMatrices._hgemv_recursive!</code></a></li><li><a href="references/#HMatrices._update_frob_norm-Tuple{Any, Any, Any}"><code>HMatrices._update_frob_norm</code></a></li><li><a href="references/#HMatrices.assemble_hmatrix-Tuple{AbstractKernelMatrix}"><code>HMatrices.assemble_hmatrix</code></a></li><li><a href="references/#HMatrices.assemble_hmatrix-Union{Tuple{T}, Tuple{Type{T}, Any, Any, Any}} where T"><code>HMatrices.assemble_hmatrix</code></a></li><li><a href="references/#HMatrices.binary_split!-Union{Tuple{T}, Tuple{N}, Tuple{ClusterTree{N, T}, Function}} where {N, T}"><code>HMatrices.binary_split!</code></a></li><li><a href="references/#HMatrices.build_sequence_partition-NTuple{4, Any}"><code>HMatrices.build_sequence_partition</code></a></li><li><a href="references/#HMatrices.center-Tuple{HyperRectangle}"><code>HMatrices.center</code></a></li><li><a href="references/#HMatrices.col_partition"><code>HMatrices.col_partition</code></a></li><li><a href="references/#HMatrices.compress!-Tuple{HMatrices.RkMatrix, TSVD}"><code>HMatrices.compress!</code></a></li><li><a href="references/#HMatrices.compress!-Tuple{Matrix, TSVD}"><code>HMatrices.compress!</code></a></li><li><a href="references/#HMatrices.compression_ratio-Tuple{HMatrices.RkMatrix}"><code>HMatrices.compression_ratio</code></a></li><li><a href="references/#HMatrices.compression_ratio-Tuple{HMatrix}"><code>HMatrices.compression_ratio</code></a></li><li><a href="references/#HMatrices.container-Tuple{ClusterTree}"><code>HMatrices.container</code></a></li><li><a href="references/#HMatrices.depth"><code>HMatrices.depth</code></a></li><li><a href="references/#HMatrices.diameter-Tuple{HyperRectangle}"><code>HMatrices.diameter</code></a></li><li><a href="references/#HMatrices.distance-Tuple{ClusterTree, ClusterTree}"><code>HMatrices.distance</code></a></li><li><a href="references/#HMatrices.distance-Union{Tuple{N}, Tuple{HyperRectangle{N}, HyperRectangle{N}}} where N"><code>HMatrices.distance</code></a></li><li><a href="references/#HMatrices.elements-Tuple{ClusterTree}"><code>HMatrices.elements</code></a></li><li><a href="references/#HMatrices.filter_tree"><code>HMatrices.filter_tree</code></a></li><li><a href="references/#HMatrices.filter_tree!"><code>HMatrices.filter_tree!</code></a></li><li><a href="references/#HMatrices.find_optimal_cost"><code>HMatrices.find_optimal_cost</code></a></li><li><a href="references/#HMatrices.find_optimal_partition"><code>HMatrices.find_optimal_partition</code></a></li><li><a href="references/#HMatrices.getblock!-NTuple{4, Any}"><code>HMatrices.getblock!</code></a></li><li><a href="references/#HMatrices.getcol!-Union{Tuple{T}, Tuple{Any, HMatrices.RkMatrix, Int64}, Tuple{Any, HMatrices.RkMatrix, Int64, Val{T}}} where T"><code>HMatrices.getcol!</code></a></li><li><a href="references/#HMatrices.glob2loc-Tuple{ClusterTree}"><code>HMatrices.glob2loc</code></a></li><li><a href="references/#HMatrices.has_partition"><code>HMatrices.has_partition</code></a></li><li><a href="references/#HMatrices.hilbert_cartesian_to_linear-Tuple{Integer, Any, Any}"><code>HMatrices.hilbert_cartesian_to_linear</code></a></li><li><a href="references/#HMatrices.hilbert_linear_to_cartesian-Tuple{Integer, Any}"><code>HMatrices.hilbert_linear_to_cartesian</code></a></li><li><a href="references/#HMatrices.hilbert_partition"><code>HMatrices.hilbert_partition</code></a></li><li><a href="references/#HMatrices.hmul!-Union{Tuple{T}, Tuple{T, T, T, Any, Any, Any}, Tuple{T, T, T, Vararg{Any, 4}}} where T&lt;:HMatrix"><code>HMatrices.hmul!</code></a></li><li><a href="references/#HMatrices.index_range-Tuple{ClusterTree}"><code>HMatrices.index_range</code></a></li><li><a href="references/#HMatrices.isclean-Tuple{HMatrix}"><code>HMatrices.isclean</code></a></li><li><a href="references/#HMatrices.loc2glob-Tuple{ClusterTree}"><code>HMatrices.loc2glob</code></a></li><li><a href="references/#HMatrices.newcol!-Tuple{HMatrices.VectorOfVectors}"><code>HMatrices.newcol!</code></a></li><li><a href="references/#HMatrices.num_stored_elements-Tuple{HMatrices.RkMatrix}"><code>HMatrices.num_stored_elements</code></a></li><li><a href="references/#HMatrices.num_stored_elements-Tuple{HMatrix}"><code>HMatrices.num_stored_elements</code></a></li><li><a href="references/#HMatrices.radius-Tuple{HyperRectangle}"><code>HMatrices.radius</code></a></li><li><a href="references/#HMatrices.reset!-Tuple{HMatrices.VectorOfVectors}"><code>HMatrices.reset!</code></a></li><li><a href="references/#HMatrices.root_elements-Tuple{ClusterTree}"><code>HMatrices.root_elements</code></a></li><li><a href="references/#HMatrices.row_partition"><code>HMatrices.row_partition</code></a></li><li><a href="references/#HMatrices.should_split"><code>HMatrices.should_split</code></a></li><li><a href="references/#HMatrices.split!"><code>HMatrices.split!</code></a></li><li><a href="references/#HMatrices.use_global_index-Tuple{}"><code>HMatrices.use_global_index</code></a></li><li><a href="references/#HMatrices.use_threads-Tuple{}"><code>HMatrices.use_threads</code></a></li><li><a href="references/#LinearAlgebra.lu-Tuple{HMatrix, Vararg{Any}}"><code>LinearAlgebra.lu</code></a></li><li><a href="references/#LinearAlgebra.lu!-Tuple{HMatrix}"><code>LinearAlgebra.lu!</code></a></li><li><a href="references/#LinearAlgebra.lu!-Tuple{HMatrix, Any}"><code>LinearAlgebra.lu!</code></a></li><li><a href="references/#LinearAlgebra.mul!"><code>LinearAlgebra.mul!</code></a></li></ul></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="kernelmatrix/">Kernel matrices »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Monday 13 May 2024 14:22">Monday 13 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
